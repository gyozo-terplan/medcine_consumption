{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWPHx39OZUSU",
        "outputId": "0fd24118-52ca-4578-a499-e211188ed371"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dbfread"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9REQXXDy31M",
        "outputId": "bd4c917c-efab-40b4-cc04-e0d649bc08b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dbfread\n",
            "  Downloading dbfread-2.0.7-py2.py3-none-any.whl (20 kB)\n",
            "Installing collected packages: dbfread\n",
            "Successfully installed dbfread-2.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aULCxfNqYf-X"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "from os.path import exists\n",
        "from pathlib import Path\n",
        "import urllib.request\n",
        "from dbfread import DBF\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j624Ku7Nb_Px"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/files.txt'\n",
        "download_path = '/content/drive/MyDrive/medcine'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kdqRMsC9bx78"
      },
      "outputs": [],
      "source": [
        "def get_links(path):\n",
        "\n",
        "  \"\"\"\n",
        "    Reads a file containing the list of data files\n",
        "    Arguments:\n",
        "        path: file path of the file\n",
        "    Returns:\n",
        "        List of urls to be downloaded\n",
        "  \"\"\"\n",
        "\n",
        "  url_file = open(path, \"r\")\n",
        "  urls = url_file.read().split('\\n')\n",
        "\n",
        "  return urls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download(urls,download_path):\n",
        "\n",
        "  \"\"\"\n",
        "    Reads the list of urls and download the files to the given path\n",
        "    Arguments:\n",
        "        urls: list of files to be downloaded\n",
        "        download_path: file path to use for downloading zipped data files\n",
        "    \n",
        "  \"\"\"\n",
        "\n",
        "  no_of_files = len(urls) \n",
        "\n",
        "  for i, u in enumerate(urls):\n",
        "    full_path = os.path.join(download_path, u.split('/')[-1])\n",
        "    if exists(full_path): \n",
        "      continue\n",
        "      \n",
        "    urllib.request.urlretrieve(u, full_path)\n",
        "    print(f'{u} downloaded successfully! {i+1}/{no_of_files}')"
      ],
      "metadata": {
        "id": "EYrO6K8Xrfbk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def files_to_extract(file_path):\n",
        "\n",
        "  \"\"\"\n",
        "    Finds files to be unzipped\n",
        "    Arguments:\n",
        "        file_path: file paths of files to be unzipped\n",
        "    Returns:\n",
        "        List of files to be unzipped\n",
        "  \"\"\"\n",
        "\n",
        "  files = [f for f in os.listdir(file_path) \n",
        "                      if (f.endswith('zip') or f.endswith('ZIP'))]\n",
        "\n",
        "  return files"
      ],
      "metadata": {
        "id": "czgf_nUNq1Wk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conversion(file_path,files):\n",
        "\n",
        "  \"\"\"\n",
        "    Unzip data files and combine them into one parquette file\n",
        "    Arguments:\n",
        "        files: list of files to be unzipped\n",
        "        file_path: file path of the resulting data file \n",
        "  \"\"\"\n",
        "\n",
        "  results=pd.DataFrame()\n",
        "\n",
        "  for file in files:\n",
        "\n",
        "    print(file+' to extract!')\n",
        "\n",
        "    with zipfile.ZipFile(os.path.join(file_path, file), 'r') as zip_ref:\n",
        "      \n",
        "      files_in_zip = zip_ref.namelist()\n",
        "      data_file = [x for x in files_in_zip if x.find('BETEGSZAMOK_ATC')!=-1][0]\n",
        "      data = zip_ref.read(data_file)\n",
        "      path = Path(file_path) / Path(data_file).name\n",
        "      path.write_bytes(data)\n",
        "    \n",
        "    try:\n",
        "      table = DBF(Path(file_path) / Path(data_file).name,ignore_missing_memofile=True)\n",
        "      frame = pd.DataFrame(iter(table))\n",
        "\n",
        "    except UnicodeDecodeError:\n",
        "      table = DBF(Path(file_path) / Path(data_file).name,encoding='latin1',ignore_missing_memofile=True)\n",
        "      frame = pd.DataFrame(iter(table)) \n",
        "\n",
        "    filename = file.split('.')[0][:6] ##first 6 digit of the filename\n",
        "    \n",
        "\n",
        "    try:\n",
        "      patient_no_col = [x for x in list(frame) if filename in x ][0]\n",
        "    except: \n",
        "      print('missing column!')\n",
        "      continue\n",
        "\n",
        "    \n",
        "    frame['month'] = patient_no_col.split('_')[1]\n",
        "    frame.rename(columns = {patient_no_col:'patient_count'}, inplace = True)\n",
        "\n",
        "    os.remove(Path(file_path) / Path(data_file).name)\n",
        "\n",
        "    cols_to_drop = [x for x in list(frame) if x not in ['month','ATC','ATCNEV','patient_count']]\n",
        "    frame.drop(cols_to_drop,axis=1,inplace=True)\n",
        "    \n",
        "    results = results.append(frame)\n",
        "    print(file+' conversion complete!')\n",
        "\n",
        "  results.to_parquet(os.path.join(file_path, 'patients')+'.parquet')\n",
        "\n",
        "  print('patients file saved!')"
      ],
      "metadata": {
        "id": "Zd1G1xPVs_9E"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Bk4fH-rnhemA"
      },
      "outputs": [],
      "source": [
        "def data_prep(path,download_path):\n",
        "\n",
        "  \"\"\"\n",
        "    Runs the data prep pipeline\n",
        "    Arguments:\n",
        "        path: path of the file containing the urls of the files to be downloaded \n",
        "        download_path: file path where files to be downloaded and resulting parquette file to be exported\n",
        "  \"\"\"\n",
        "\n",
        "  urls = get_links(path)\n",
        "  download(urls,download_path)\n",
        "  files = files_to_extract(download_path)\n",
        "\n",
        "  conversion(download_path,files)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_prep(path,download_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2USDd-OUyagK",
        "outputId": "cb3b18b6-d5a3-41e9-b88b-fbd777d0dcb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "201512.zip to extract!\n",
            "201512.zip conversion complete!\n",
            "201511.zip to extract!\n",
            "201511.zip conversion complete!\n",
            "201510.zip to extract!\n",
            "201510.zip conversion complete!\n",
            "201509.zip to extract!\n",
            "201509.zip conversion complete!\n",
            "201508.zip to extract!\n",
            "201508.zip conversion complete!\n",
            "201507.zip to extract!\n",
            "201507.zip conversion complete!\n",
            "201506.zip to extract!\n",
            "201506.zip conversion complete!\n",
            "201505.zip to extract!\n",
            "201505.zip conversion complete!\n",
            "201504.zip to extract!\n",
            "201504.zip conversion complete!\n",
            "201503.zip to extract!\n",
            "201503.zip conversion complete!\n",
            "201502.zip to extract!\n",
            "201502.zip conversion complete!\n",
            "201501.zip to extract!\n",
            "201501.zip conversion complete!\n",
            "201612.zip to extract!\n",
            "201612.zip conversion complete!\n",
            "201611.zip to extract!\n",
            "201611.zip conversion complete!\n",
            "201610.zip to extract!\n",
            "201610.zip conversion complete!\n",
            "201609.zip to extract!\n",
            "201609.zip conversion complete!\n",
            "201608.zip to extract!\n",
            "201608.zip conversion complete!\n",
            "201607.zip to extract!\n",
            "201607.zip conversion complete!\n",
            "201606.zip to extract!\n",
            "201606.zip conversion complete!\n",
            "201605.zip to extract!\n",
            "201605.zip conversion complete!\n",
            "201604.zip to extract!\n",
            "201604.zip conversion complete!\n",
            "201603.zip to extract!\n",
            "201603.zip conversion complete!\n",
            "201602.zip to extract!\n",
            "201602.zip conversion complete!\n",
            "201601.zip to extract!\n",
            "201601.zip conversion complete!\n",
            "201712.zip to extract!\n",
            "201712.zip conversion complete!\n",
            "201711.zip to extract!\n",
            "201711.zip conversion complete!\n",
            "201710.zip to extract!\n",
            "201710.zip conversion complete!\n",
            "201709.zip to extract!\n",
            "201709.zip conversion complete!\n",
            "201708.zip to extract!\n",
            "201708.zip conversion complete!\n",
            "201707.zip to extract!\n",
            "201707.zip conversion complete!\n",
            "201706.zip to extract!\n",
            "201706.zip conversion complete!\n",
            "201705.zip to extract!\n",
            "201705.zip conversion complete!\n",
            "201704.zip to extract!\n",
            "201704.zip conversion complete!\n",
            "201703.zip to extract!\n",
            "201703.zip conversion complete!\n",
            "201702.zip to extract!\n",
            "201702.zip conversion complete!\n",
            "201701.zip to extract!\n",
            "201701.zip conversion complete!\n",
            "201812.ZIP to extract!\n",
            "201812.ZIP conversion complete!\n",
            "201811.ZIP to extract!\n",
            "201811.ZIP conversion complete!\n",
            "201810.ZIP to extract!\n",
            "201810.ZIP conversion complete!\n",
            "201809.ZIP to extract!\n",
            "201809.ZIP conversion complete!\n",
            "201808.ZIP to extract!\n",
            "missing column!\n",
            "201807.ZIP to extract!\n",
            "201807.ZIP conversion complete!\n",
            "201806.zip to extract!\n",
            "201806.zip conversion complete!\n",
            "201805.zip to extract!\n",
            "201805.zip conversion complete!\n",
            "201804.zip to extract!\n",
            "201804.zip conversion complete!\n",
            "201803.zip to extract!\n",
            "201803.zip conversion complete!\n",
            "201802.zip to extract!\n",
            "201802.zip conversion complete!\n",
            "201801.zip to extract!\n",
            "201801.zip conversion complete!\n",
            "201912.ZIP to extract!\n",
            "201912.ZIP conversion complete!\n",
            "201911.ZIP to extract!\n",
            "201911.ZIP conversion complete!\n",
            "201910.ZIP to extract!\n",
            "201910.ZIP conversion complete!\n",
            "201909.ZIP to extract!\n",
            "201909.ZIP conversion complete!\n",
            "201908.ZIP to extract!\n",
            "201908.ZIP conversion complete!\n",
            "201907.ZIP to extract!\n",
            "201907.ZIP conversion complete!\n",
            "201906.ZIP to extract!\n",
            "201906.ZIP conversion complete!\n",
            "201905.ZIP to extract!\n",
            "201905.ZIP conversion complete!\n",
            "201904.ZIP to extract!\n",
            "201904.ZIP conversion complete!\n",
            "201903.zip to extract!\n",
            "201903.zip conversion complete!\n",
            "201902.ZIP to extract!\n",
            "201902.ZIP conversion complete!\n",
            "201901.ZIP to extract!\n",
            "201901.ZIP conversion complete!\n",
            "202012.ZIP to extract!\n",
            "202012.ZIP conversion complete!\n",
            "202011.ZIP to extract!\n",
            "202011.ZIP conversion complete!\n",
            "202010.ZIP to extract!\n",
            "202010.ZIP conversion complete!\n",
            "202009.ZIP to extract!\n",
            "202009.ZIP conversion complete!\n",
            "202008.ZIP to extract!\n",
            "202008.ZIP conversion complete!\n",
            "202007.ZIP to extract!\n",
            "202007.ZIP conversion complete!\n",
            "202006.ZIP to extract!\n",
            "202006.ZIP conversion complete!\n",
            "202005.ZIP to extract!\n",
            "202005.ZIP conversion complete!\n",
            "202004.ZIP to extract!\n",
            "202004.ZIP conversion complete!\n",
            "202003.ZIP to extract!\n",
            "202003.ZIP conversion complete!\n",
            "202002.ZIP to extract!\n",
            "202002.ZIP conversion complete!\n",
            "202001.ZIP to extract!\n",
            "202001.ZIP conversion complete!\n",
            "202101.ZIP to extract!\n",
            "202101.ZIP conversion complete!\n",
            "202102.zip to extract!\n",
            "202102.zip conversion complete!\n",
            "202103.zip to extract!\n",
            "202103.zip conversion complete!\n",
            "202104.zip to extract!\n",
            "202104.zip conversion complete!\n",
            "202105.zip to extract!\n",
            "202105.zip conversion complete!\n",
            "202106v2.zip to extract!\n",
            "202106v2.zip conversion complete!\n",
            "202107v2.zip to extract!\n",
            "202107v2.zip conversion complete!\n",
            "202108.zip to extract!\n",
            "202108.zip conversion complete!\n",
            "202109.zip to extract!\n",
            "202109.zip conversion complete!\n",
            "202110.zip to extract!\n",
            "202110.zip conversion complete!\n",
            "202111.zip to extract!\n",
            "202111.zip conversion complete!\n",
            "patients file saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kll6HUbsXBAI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "medcine_data_prep.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
